covs26 <- c(
"X_Agecat_0m","X_Education_0m","X_Ethnicity_0m","X_Socialsupport_0m",
"X_TB_status_0m","X_OI_index_0m","X_weight_0m","X_CD4_0m",
"X_viral_load_0m","X_Adherence_0m"
)
# 3) Identify numeric vs. categorical
num_covs26 <- df26 %>% select(all_of(covs26)) %>% select(where(is.numeric)) %>% names()
cat_covs26 <- setdiff(covs26, num_covs26)
# 4) Impute missing covariates
df26 <- df26 %>%
mutate(across(all_of(num_covs26),
~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(all_of(cat_covs26),
~ {
m <- names(sort(table(.[!is.na(.)]), decreasing = TRUE))[1]
replace(., is.na(.), m)
}))
# 5) Build regression formula
f26 <- as.formula(paste("Y ~ A +", paste(covs26, collapse = " + ")))
# 6) ANCOVA (in‐sample MSE)
fit26_anc      <- lm(f26, data = df26)
s26            <- summary(fit26_anc)
beta26         <- s26$coefficients["A","Estimate"]
se26           <- s26$coefficients["A","Std. Error"]
df26$yhat26_anc <- predict(fit26_anc, df26)
mse26_anc      <- mean((df26$yhat26_anc - df26$Y)^2)
# 7) Counterfactual regression (in‐sample MSE + ATE)
df26_cf <- df26 %>%
mutate(
Z1 = ifelse(A == 0, chatgpt_Dadh_6m_cf, 0),
Z0 = ifelse(A == 1, chatgpt_Dadh_6m_cf, 0)
)
fit26_cf       <- lm(update(f26, . ~ . + Z1 + Z0), data = df26_cf)
df26$yhat26_cf <- predict(fit26_cf, df26_cf)
mse26_cf       <- mean((df26$yhat26_cf - df26$Y)^2)
# → Correct CF‐regression ATE using group‐specific means
coefs_cf26 <- coef(fit26_cf)
m1_cf26    <- mean(df26_cf$Z1[df26_cf$A == 0])
m0_cf26    <- mean(df26_cf$Z0[df26_cf$A == 1])
ate26_cf   <- coefs_cf26["A"] +
coefs_cf26["Z1"] * m1_cf26 -
coefs_cf26["Z0"] * m0_cf26
# 8) HAIPW stacking
res26 <- haipw_stack(
df26, "Reminder module", "Y", covs26,
list(
chatgpt  = c("chatgpt_Δadh_6m_1", "chatgpt_Δadh_6m_0"),
deepseek = c("ds_Δadh_6m_1",       "ds_Δadh_6m_0")
)
)
# 9) Random Forest — OOB MSE
fit26_rf     <- ranger(f26, data = df26,
num.trees = 500,
respect.unordered.factors = "order",
seed = 2025)
oob_mse26_rf <- fit26_rf$prediction.error
# 10) Bootstrap SE of the CF‐regression ATE (B = 500)
B         <- 500
boot_cf26 <- numeric(0)
while (length(boot_cf26) < B) {
idx    <- sample(nrow(df26_cf), replace = TRUE)
bdf_cf <- df26_cf[idx, ]
fit_b  <- lm(update(f26, . ~ . + Z1 + Z0), data = bdf_cf)
coefs  <- coef(fit_b)
cf_try <- coefs["A"] +
coefs["Z1"] * mean(bdf_cf$Z1[bdf_cf$A == 0]) -
coefs["Z0"] * mean(bdf_cf$Z0[bdf_cf$A == 1])
if (!is.na(cf_try)) boot_cf26 <- c(boot_cf26, cf_try)
}
se26_cf_boot <- sd(boot_cf26)
# 11) Store results (includes CF ATE & SE)
store_results(
"26",
beta26,      se26,           # ANCOVA
res26$ate,   res26$se,       # HAIPW ATE
ate26_cf,    se26_cf_boot,   # CF‐regression ATE & SE
mse26_anc,   mse26_cf,       # MSEs
oob_mse26_rf                     # RF OOB‐MSE
)
# 12) Quick summary of SE’s
cat("SE(ANCOVA):          ", round(se26,         3), "\n")
cat("SE(HAIPW stacking):   ", round(res26$se,     3), "\n")
cat("SE(CF regression):    ", round(se26_cf_boot, 3), "\n")
# trial33_full_analysis.R
library(data.table)
library(dplyr)
library(ranger)
set.seed(2025)
# 0) Load raw data & ChatGPT CF files
df33_raw    <- fread("trial 33/trial33.csv")
chat33_orig <- fread("trial 33/trial33_gpt-4.1_counterfactuals.csv") %>%
rename(
chatgpt_y1 = `gpt-4.1_TMscore_6m_R`,
chatgpt_y0 = `gpt-4.1_TMscore_6m_S`
)
chat33_cf   <- fread("trial 33/trial33_gpt-4.1_cf.csv") %>%
rename(chat_cf = `chatgpt_cf_TMscore_6m`)
# 1) Combine, define treatment & outcome, drop missing
df33 <- bind_cols(chat33_orig, chat33_cf) %>%
mutate(
A = ifelse(Treatment == "Reframing", 1, 0),
Y = YP_TM_total_score
) %>%
filter(!is.na(A), !is.na(Y))
# 2) Baseline covariates
covs33 <- grep("_0w$", names(df33), value = TRUE)
# 3) Identify numeric vs categorical
num_covs33 <- df33 %>% select(all_of(covs33)) %>% select(where(is.numeric)) %>% names()
cat_covs33 <- setdiff(covs33, num_covs33)
# 4) Impute missing covariates
df33 <- df33 %>%
mutate(across(all_of(num_covs33),
~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(all_of(cat_covs33),
~ replace(., is.na(.),
names(sort(table(.[!is.na(.)]), decreasing = TRUE))[1])))
# 5) Reconstruct both‐arm potential outcomes for HAIPW
df33 <- df33 %>%
mutate(
chatgpt_y1 = ifelse(A == 1, Y, chat_cf),
chatgpt_y0 = ifelse(A == 0, Y, chat_cf)
)
# 6) Build regression formula
f33 <- if (length(covs33) > 0) {
as.formula(paste("Y ~ A +", paste(covs33, collapse = " + ")))
} else {
as.formula("Y ~ A")
}
# 7) ANCOVA (in‐sample MSE)
fit33_anc     <- lm(f33, data = df33)
beta33        <- coef(summary(fit33_anc))["A","Estimate"]
se33          <- coef(summary(fit33_anc))["A","Std. Error"]
df33$yhat_anc <- predict(fit33_anc, df33)
mse33_anc     <- mean((df33$yhat_anc - df33$Y)^2)
# 8) Counterfactual regression (in‐sample MSE + ATE)
df33_cf       <- df33 %>%
mutate(
Z1 = ifelse(A == 0, chat_cf, 0),
Z0 = ifelse(A == 1, chat_cf, 0)
)
fit33_cf      <- lm(update(f33, . ~ . + Z1 + Z0), data = df33_cf)
df33$yhat_cf  <- predict(fit33_cf, df33_cf)
mse33_cf      <- mean((df33$yhat_cf - df33$Y)^2)
# → Correct CF‐regression ATE using group‐specific means
coefs_cf33 <- coef(fit33_cf)
m1_cf33    <- mean(df33_cf$Z1[df33_cf$A == 0])
m0_cf33    <- mean(df33_cf$Z0[df33_cf$A == 1])
ate33_cf   <- coefs_cf33["A"] +
coefs_cf33["Z1"] * m1_cf33 -
coefs_cf33["Z0"] * m0_cf33
# 9) HAIPW stacking
res33 <- haipw_stack(
df33, "Reframing", "Y", covs33,
list(chatgpt = c("chatgpt_y1","chatgpt_y0"))
)
# 10) Random Forest – OOB MSE
fit33_rf      <- ranger(f33, data = df33, num.trees = 500,
respect.unordered.factors = "order",
seed = 2025)
oob_mse33_rf  <- fit33_rf$prediction.error
# 11) Bootstrap SE of CF‐regression ATE (B = 500)
B           <- 500
boot33      <- numeric(0)
while (length(boot33) < B) {
idx    <- sample(nrow(df33_cf), replace = TRUE)
bdf    <- df33_cf[idx, ]
fit_b  <- lm(update(f33, . ~ . + Z1 + Z0), data = bdf)
coefs  <- coef(fit_b)
cf_try <- coefs["A"] +
coefs["Z1"] * mean(bdf$Z1[bdf$A == 0]) -
coefs["Z0"] * mean(bdf$Z0[bdf$A == 1])
if (!is.na(cf_try)) boot33 <- c(boot33, cf_try)
}
se33_cf_boot <- sd(boot33)
# 12) Store results (includes CF ATE & SE)
store_results(
"33",
beta33,      se33,          # ANCOVA
res33$ate,   res33$se,      # HAIPW ATE & SE
ate33_cf,    se33_cf_boot,  # CF regression ATE & SE
mse33_anc,   mse33_cf,      # in‐sample MSEs
oob_mse33_rf                   # RF OOB‐MSE
)
# 13) Quick summary of SE’s
cat("SE(ANCOVA):          ", round(se33,        3), "\n")
cat("SE(HAIPW stacking):   ", round(res33$se,    3), "\n")
cat("SE(CF regression):    ", round(se33_cf_boot,3), "\n")
summary(fit33_cf)
# trial35_full_analysis.R
set.seed(2025)
# 0) Load raw data & prediction files
df35_raw      <- fread("trial 35/trial35.csv")
chat35_uncond <- fread("trial 35/trial35_unconditional_predictions.csv")
ds35          <- fread("trial 35/trial35_deepseek_potential_outcomes.csv")
cf35          <- fread("trial 35/trial35_counterfactual_predictions.csv") %>%
rename(chat_cf = names(.)[!names(.) %in% c(names(df35_raw),
names(chat35_uncond),
names(ds35))])
# 1) Combine, define A & Y, drop only missing
df35 <- df35_raw %>%
mutate(
A = ifelse(Treatment == "Exercise", 1, 0),
Y = YP_delta_Total_weight_gain_delivery
) %>%
filter(!is.na(A), !is.na(Y)) %>%
bind_cols(chat35_uncond, ds35, cf35)
# 2) Baseline covariates
covs35 <- c(
"X_preg_BMI_0w", "X_BMI_0w", "X_PGWB_index_0w",
"X_Anxiety_0w", "X_Depressed_0w", "X_Pos_Wellbeing_0w",
"X_Self_control_0w", "X_General_Health_0w", "X_Vitality_0w"
)
# 3) Impute missing covariates
num_covs35 <- df35 %>% select(all_of(covs35)) %>% select(where(is.numeric)) %>% names()
cat_covs35 <- setdiff(covs35, num_covs35)
df35 <- df35 %>%
mutate(across(all_of(num_covs35),
~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(all_of(cat_covs35),
~ {
m <- names(sort(table(.[!is.na(.)]), decreasing = TRUE))[1]
replace(., is.na(.), m)
}))
# 4) Reconstruct both-arm ChatGPT predictions for HAIPW
df35 <- df35 %>%
mutate(
chatgpt_y1 = ifelse(A == 1, Y, chat_cf),
chatgpt_y0 = ifelse(A == 0, Y, chat_cf)
)
# 5) Build regression formula
f35 <- as.formula(paste("Y ~ A +", paste(covs35, collapse = " + ")))
# 6) ANCOVA (in-sample MSE)
fit35_anc      <- lm(f35, data = df35)
beta35         <- coef(summary(fit35_anc))["A","Estimate"]
se35           <- coef(summary(fit35_anc))["A","Std. Error"]
df35$yhat35_anc <- predict(fit35_anc, df35)
mse35_anc      <- mean((df35$yhat35_anc - df35$Y)^2)
# 7) Counterfactual regression (in-sample MSE + ATE)
df35_cf        <- df35 %>%
mutate(
Z1 = ifelse(A == 0, chat_cf, 0),
Z0 = ifelse(A == 1, chat_cf, 0)
)
fit35_cf       <- lm(update(f35, . ~ . + Z1 + Z0), data = df35_cf)
df35$yhat35_cf <- predict(fit35_cf, df35_cf)
mse35_cf       <- mean((df35$yhat35_cf - df35$Y)^2)
# → Correct CF-regression ATE using group-specific means
coefs_cf35 <- coef(fit35_cf)
m1_cf35    <- mean(df35_cf$Z1[df35_cf$A == 0])
m0_cf35    <- mean(df35_cf$Z0[df35_cf$A == 1])
ate35_cf   <- coefs_cf35["A"] +
coefs_cf35["Z1"] * m1_cf35 -
coefs_cf35["Z0"] * m0_cf35
# 8) HAIPW stacking
res35 <- haipw_stack(
df35, "Exercise", "Y", covs35,
list(
chatgpt  = c("chatgpt_y1","chatgpt_y0"),
deepseek = c("deepseek_y1","deepseek_y0")
)
)
# 9) Random Forest — OOB MSE
fit35_rf     <- ranger(f35, data = df35,
num.trees = 500,
respect.unordered.factors = "order",
seed = 2025)
oob_mse35_rf <- fit35_rf$prediction.error
# 10) Bootstrap SE of CF-regression ATE (B = 500)
B          <- 500
boot_cf35  <- numeric(0)
while(length(boot_cf35) < B) {
idx     <- sample(nrow(df35_cf), replace = TRUE)
bdf_cf  <- df35_cf[idx, ]
fit_b   <- lm(update(f35, . ~ . + Z1 + Z0), data = bdf_cf)
coefs   <- coef(fit_b)
cf_try  <- coefs["A"] +
coefs["Z1"] * mean(bdf_cf$Z1[bdf_cf$A == 0]) -
coefs["Z0"] * mean(bdf_cf$Z0[bdf_cf$A == 1])
if(!is.na(cf_try)) boot_cf35 <- c(boot_cf35, cf_try)
}
se35_cf_boot <- sd(boot_cf35)
# 11) Store results (includes CF ATE & SE)
store_results(
"35",
beta35,        se35,          # ANCOVA
res35$ate,     res35$se,      # HAIPW ATE & SE
ate35_cf,      se35_cf_boot,  # CF regression ATE & SE
mse35_anc,     mse35_cf,      # in-sample MSEs
oob_mse35_rf                    # RF OOB-MSE
)
# 12) Quick summary of SE’s
cat("SE(ANCOVA):          ", round(se35,        3), "\n")
cat("SE(HAIPW stacking):   ", round(res35$se,    3), "\n")
cat("SE(CF regression):    ", round(se35_cf_boot,3), "\n")
# trial36_full_analysis.R
library(data.table)
library(dplyr)
library(ranger)
set.seed(2025)
# 0) Load two CF sources
chat36_orig <- fread("trial 36/trial36_gpt-4.1_counterfactuals.csv") %>%
rename(
chatgpt_y1 = `gpt-4.1_ΔAttentionExe_12m_ACI`,
chatgpt_y0 = `gpt-4.1_ΔAttentionExe_12m_PI`
)%>%
filter(Treatment %in% c("ACI", "PI"))
o4mini_cf   <- fread("trial 36/trial36_o4-mini_cf.csv") %>%
rename(chat_cf = names(.)[1])
# 1) Combine, define treatment & outcome, drop missing
df36 <- bind_cols( chat36_orig, o4mini_cf) %>%
filter(Treatment %in% c("ACI", "PI")) %>%
mutate(
A = ifelse(Treatment == "ACI", 1, 0),
Y = YP_delta_AttentionExe_12m
) %>%
filter(!is.na(A), !is.na(Y))
# 2) Baseline covariates
covs36 <- c(
"X_GDS_0m","X_EMQ_0m","X_STAI_0m","X_MMSE_0m",
"X_RAVLT_delayedrecall_0m","X_IPAQ_total_0m","X_MeDi_score_0m",
"X_MemoryNew_0m","X_AttentionExe_0m","X_VisuoSpNew_0m"
)
# 3) Impute missing covariates (median for numeric, mode for categorical)
num_covs36 <- df36 %>% select(all_of(covs36)) %>% select(where(is.numeric)) %>% names()
cat_covs36 <- setdiff(covs36, num_covs36)
df36 <- df36 %>%
mutate(across(all_of(num_covs36),
~ ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))) %>%
mutate(across(all_of(cat_covs36),
~ replace(., is.na(.),
names(sort(table(.[!is.na(.)]), decreasing = TRUE))[1])))
# 4) Reconstruct both‐arm ChatGPT predictions for HAIPW
df36 <- df36 %>%
mutate(
chatgpt_y1 = ifelse(A == 1, Y, chat_cf),
chatgpt_y0 = ifelse(A == 0, Y, chat_cf)
)
# 5) Build regression formula
f36 <- as.formula(paste("Y ~ A +", paste(covs36, collapse = " + ")))
# 6) ANCOVA (in‐sample MSE)
fit36_anc      <- lm(f36, data = df36)
s36_anc        <- summary(fit36_anc)
beta36         <- s36_anc$coefficients["A","Estimate"]
se36           <- s36_anc$coefficients["A","Std. Error"]
df36$yhat36_anc <- predict(fit36_anc, df36)
mse36_anc      <- mean((df36$yhat36_anc - df36$Y)^2)
# 7) Counterfactual regression (in‐sample MSE + ATE)
df36_cf <- df36 %>%
mutate(
Z1 = ifelse(A == 0, chat_cf, 0),
Z0 = ifelse(A == 1, chat_cf, 0)
)
fit36_cf        <- lm(update(f36, . ~ . + Z1 + Z0), data = df36_cf)
df36$yhat36_cf  <- predict(fit36_cf, df36_cf)
mse36_cf        <- mean((df36$yhat36_cf - df36$Y)^2)
# → Correct CF‐regression ATE using group‐specific means
coefs_cf36 <- coef(fit36_cf)
m1_cf36    <- mean(df36_cf$Z1[df36_cf$A == 0])
m0_cf36    <- mean(df36_cf$Z0[df36_cf$A == 1])
ate36_cf   <- coefs_cf36["A"] +
coefs_cf36["Z1"] * m1_cf36 -
coefs_cf36["Z0"] * m0_cf36
# 8) HAIPW stacking
res36 <- haipw_stack(
df36, "ACI", "Y", covs36,
list(chatgpt = c("chatgpt_y1", "chatgpt_y0"))
)
# 9) Random Forest — OOB MSE
fit36_rf     <- ranger(f36, data = df36,
num.trees = 500,
respect.unordered.factors = "order",
seed = 2025)
oob_mse36_rf <- fit36_rf$prediction.error
# 10) Bootstrap SE of CF‐regression ATE (B = 500)
B      <- 500
boot36 <- numeric(0)
while (length(boot36) < B) {
idx    <- sample(nrow(df36_cf), replace = TRUE)
bdf    <- df36_cf[idx, ]
fit_b  <- lm(update(f36, . ~ . + Z1 + Z0), data = bdf)
coefs  <- coef(fit_b)
cf_try <- coefs["A"] +
coefs["Z1"] * mean(bdf$Z1[bdf$A == 0]) -
coefs["Z0"] * mean(bdf$Z0[bdf$A == 1])
if (!is.na(cf_try)) boot36 <- c(boot36, cf_try)
}
se36_cf_boot <- sd(boot36)
# 11) Store results (includes CF‐regression ATE & SE)
store_results(
"36",
beta36,        se36,         # ANCOVA
res36$ate,     res36$se,     # HAIPW ATE & SE
ate36_cf,      se36_cf_boot, # CF‐regression ATE & SE
mse36_anc,     mse36_cf,     # in‐sample MSEs
oob_mse36_rf                  # RF OOB‐MSE
)
# 12) Quick summary of SE’s
cat("SE(ANCOVA):          ", round(se36,        3), "\n")
cat("SE(HAIPW stacking):   ", round(res36$se,    3), "\n")
cat("SE(CF regression):    ", round(se36_cf_boot,3), "\n")
library(dplyr)
library(readxl)
library(xtable)
library(ggplot2)
# 0) Read metadata → Trial & TrialName
meta <- read_excel("meta_data.xlsx") %>%
transmute(
Trial     = as.character(Trial_ID),
TrialName = `Trial Number/Name`
)
# 1) Combine stored results
mse_all <- bind_rows(mse_list)
se_all  <- bind_rows(se_list)
ate_all <- bind_rows(ate_list)
# 2) Recalculate sample sizes
sample_size <- tibble(
Trial = meta$Trial[c(2,4,6,14,17,19,26,33,35,36)],
N     = c(
nrow(df2),  nrow(df4),  nrow(df6),
nrow(df14), nrow(df17), nrow(df18),nrow(df19),
nrow(df26), nrow(df33), nrow(df35),
nrow(df36)
)
)
library(dplyr)
library(readxl)
library(xtable)
library(ggplot2)
# 0) Read metadata → Trial & TrialName
meta <- read_excel("meta_data.xlsx") %>%
transmute(
Trial     = as.character(Trial_ID),
TrialName = `Trial Number/Name`
)
# 1) Combine stored results
mse_all <- bind_rows(mse_list)
se_all  <- bind_rows(se_list)
ate_all <- bind_rows(ate_list)
# 2) Recalculate sample sizes
sample_size <- tibble(
Trial = meta$Trial[c(2,4,6,14,17,19,26,33,35,36)],
N     = c(
nrow(df2),  nrow(df4),  nrow(df6),
nrow(df14), nrow(df17), nrow(df19),
nrow(df26), nrow(df33), nrow(df35),
nrow(df36)
)
)
# 3) Build MSE table
mse_tab <- mse_all %>%
group_by(Trial) %>%
summarise(
ANCOVA_MSE = MSE[Model == "ANCOVA"],
CF_MSE     = MSE[Model == "Counterfactual Reg."],
RF_MSE     = MSE[Model == "Random Forest (OOB)"]
) %>%
left_join(sample_size, by="Trial") %>%
left_join(meta, by="Trial") %>%
mutate(Rel.Reduction = 100 * (ANCOVA_MSE - CF_MSE) / ANCOVA_MSE) %>%
select(Trial, TrialName, N, ANCOVA_MSE, CF_MSE, RF_MSE, Rel.Reduction)
# 4) Build SE table
se_tab <- se_all %>%
group_by(Trial) %>%
summarise(
ANCOVA_SE  = SE[Estimator == "ANCOVA beta"],
HAIPW_SE   = SE[Estimator == "HAIPW ATE"],
CF_SE_Boot = SE[Estimator == "CF Bootstrap"]
) %>%
left_join(sample_size, by="Trial") %>%
left_join(meta, by="Trial") %>%
select(Trial, TrialName, N, ANCOVA_SE, HAIPW_SE, CF_SE_Boot)
# 5) Build ATE table
ate_tab <- ate_all %>%
left_join(sample_size, by="Trial") %>%
left_join(meta, by="Trial") %>%
select(Trial, TrialName, N, Estimator, Estimate, Std_Error)
# 6) Print MSE table
cat("## Pooled MSE Summary\n")
print(
xtable(
mse_tab,
digits  = c(0,0,0,0,3,3,3,2),
caption = "In-Sample ANCOVA/CF MSE, RF OOB MSE, and Relative Reduction (%)"
),
include.rownames      = FALSE,
booktabs              = TRUE,
sanitize.text.function = identity
)
# 7) Print SE table
cat("\n## Pooled SE Summary\n")
print(
xtable(
se_tab,
digits  = c(0,0,0,0,3,3,3),
caption = "ANCOVA SE, HAIPW SE, and CF-Bootstrap SE"
),
include.rownames      = FALSE,
booktabs              = TRUE,
sanitize.text.function = identity
)
# 8) Print ATE table
cat("\n## Pooled ATE Summary\n")
print(
xtable(
ate_tab,
digits  = c(0,0,0,0,2,3,3),
caption = "ATE Estimates and Bootstrap SE by Method"
),
include.rownames      = FALSE,
booktabs              = TRUE,
sanitize.text.function = identity
)
